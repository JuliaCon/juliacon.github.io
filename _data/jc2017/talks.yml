- speaker: "Adrian Salceanu"
  affiliation: "None"
  title: "Full Stack Web Development with Genie.jl"
  abstract: >
    The web is eating the world, but building modern web applications can be an intimidating task. Successful online products must be fast, beautiful and usable. Responsive, maintainable and extendable. Provide simple and flexible web APIs. Be secure. Reach virtually 100% uptime while being easy to debug, extend and update, requiring powerful logging, intelligent caching and rapid scaling strategies.

    Julia as a language has an enormous potential in the web space thanks to its concise and friendly syntax, the powerful REPL, Unicode support, cross-platform availability, the efficiently compiled code and its parallel and distributed computing capabilities. And Julia's ecosystem already provides low level libraries like HttpServer and WebSockets. But they leave the developers having to spend large amounts of time writing glue and boilerplate code: a tedious, expensive and error prone task.

    Genie is a new web framework that leverages Julia's unique combination of features and its extensive collection of packages to empower developers to create high-performance web apps in less time and with less code. It glues low level libraries and contributes its own middlewares to expose a coherent and efficient workflow and a rich API for building web applications.

    This talk will give you the guided tour of Genie, introducing the MVC stack and its main components and showing you how to quickly bootstrap a new Genie app and how to easily implement CRUD operations to expose resources over the internet, in an efficient and secure manner. You will see how easy it is to use Genie's API in tandem with Julia's modules system to hook up your code - allowing you to focus on your software's value proposition instead of wasting precious time dealing with the low level details of transporting bytes over the wire.
  bio: >
    Web developer since 2000. Architecting and building multi-tier, performance critical web apps handling large amounts of real time data since 2008. PHP, Ruby, JavaScript, F#, Elixir. Now using Julia and Genie to tackle web development's own two-language problem (productive-slow-interpreted vs unproductive-fast-compiled).

    CTO at OLBG. Startup devotee and serial tech founder. IronHack mentor, organizer of Barcelona Julia and Barcelona on Rails. Creator of Genie.jl.
  resources:
    - name: "Slides"
      url: "/2017/assets/slides/Julia_Web_Development_with_Genie--slides.zip"
- speaker: "James Fairbanks & Seth Bromberger"
  affiliation: "Georgia Tech Research Institute & Lawrence Livermore National Laboratory"
  title: "LightGraphs: Our Network, Our Story"
  abstract: >
    Our talk discusses the development and origin of LightGraphs, current features, and future developments. We introduce the package's major design choices in a historical context as a compromise between the three core LightGraphs goals of simplicity, performance, and flexibility. We highlight several areas where specific features of Julia have led to flexible and efficient implementations of graph algorithms.

    We will highlight our work in centrality measures, graph traversals, and spectral graph algorithms as examples of areas where Julia's performance and design decisions have allowed LightGraphs to provide best-in-class implementations of graph algorithms. We also discuss integration with other organizations – JuliaOpt for matching and flow problems, and the Julia data visualization ecosystem – and highlight specifically LightGraphs' potential to provide leadership on performant graph visualization.

    Finally, we speculate on the influence of Julia's focus on elegant parallel processing to future development of the package.
  bio: >
    Dr. James Fairbanks is a Research Engineer at the Georgia Tech Research Institute where he studies problems in complex networks, data analysis, and high performance computing with applications to healthcare and social phenomena.

    Seth Bromberger, a Research Scientist at Lawrence Livermore National Laboratory (https://people.llnl.gov/seth), is currently exploring the application of graph theory and machine learning to cybersecurity problems in critical infrastructure.
  resources:
    - name: "Slides"
      url: "/2017/assets/slides/lightgraphsjl.pdf"
- speaker: "Pearl Li"
  affiliation: "Federal Reserve Bank of New York"
  title: "Using Parallel Computing for Macroeconomic Forecasting at the Federal Reserve Bank of New York"
  abstract: >
    This talk will give an overview of how researchers at the Federal Reserve Bank of New York have implemented economic forecasting and other post-estimation analyses of dynamic stochastic general equilibrium (DSGE) models using Julia’s parallel computing framework. This is part of the most recent release of our DSGE.jl package, following our ports of the DSGE model solution and estimation steps from MATLAB that were presented at JuliaCon in 2016. I will discuss the technical challenges and constraints we faced in our production environment and how we used Julia’s parallel computing tools to substantially reduce both the time and memory usage required to forecast our models. I will present our experiences with the different means of parallel computing offered in Julia - including an extended attempt at using DistributedArrays.jl - and discuss what we have learned about parallelization, both in Julia and in general.

    In addition, I will provide some of our new perspectives on using Julia in a production setting at an academic and policy institution. DSGE models are sometimes called the workhorses of modern macroeconomics, applying insights from microeconomics to inform our understanding of the economy as a whole. They are used to forecast economic variables, investigate counterfactual scenarios, and understand the impact of monetary policy. The New York Fed’s DSGE model is a large-scale model of the U.S. economy, which incorporates the zero lower bound, price/wage stickiness, financial frictions, and other realistic features of the economy. Solving, estimating, and forecasting it presents a series of high-dimensional problems which are well suited for implementation in Julia.


    Disclaimer: This talk reflects the experience of the author and does not represent an endorsement by the Federal Reserve Bank of New York or the Federal Reserve System of any particular product or service. The views expressed in this talk are those of the authors and do not necessarily reflect the position of the Federal Reserve Bank of New York or the Federal Reserve System. Any errors or omissions are the responsibility of the authors.
  bio: >
    I'm a Research Analyst at the New York Fed using Julia to estimate and forecast macroeconomic models. I'm interested in applying the frontier of scientific computing to economic research, so that we can solve more realistic and complex models.
  resources:
    - name: "Slides"
      url: "https://github.com/pearlzli/dsge-forecasting_juliacon-2017"
- speaker: "David P. Sanders"
  affiliation: "Department of Physics, Faculty of Sciences, National University of Mexico"
  title: "Equations, inequalities and global optimisation: guaranteed solutions using interval methods and constraint propagation"
  abstract: >
    How can we find all solutions of a system of nonlinear equations, the "feasible set" satisfied by a collection of 
    inequalities, or the global optimum of a complicated function? These are all known to be hard problems in numerical analysis.
    
    In this talk, we will show how to solve all of these problems, in a guaranteed way, using a collection of related methods
    based on interval arithmetic, provided by the `IntervalArithmetic.jl` package. The starting point is a simple
    dimension-independent bisection code, which can be enhanced in a variety of ways. This method is rigorous: it is 
    guaranteed to find all roots, or to find the global minimum, respectively.
    
    One key idea is the use of continuous constraint propagation, which allows us to remove large portions of the search space 
    that are infeasible. We will explain the basics of this method, in particular the 
    "forward-backward contractor", and describe the implementation in the `IntervalConstraintProgramming.jl` package.

    This package generates forward and backward code automatically from a Julia expression, using metaprogramming techniques. 
    These are combined into "contractors", i.e. operators that contract a box without removing any portion of the set of 
    interest. These, in turn, give 
    a rigorous answer to the question whether a given box lies inside the feasible set or not. In this way, a paving 
    (collection of boxes) is built up that approximates the set.

  bio: >
    David P. Sanders is associate professor of computational physics in the Department of Physics of the Faculty of Sciences at the National University of Mexico in Mexico City.

    His video tutorials on Julia have a total of 75,000 views on YouTube.
    He is a principal author of the [`ValidatedNumerics.jl`](https://github.com/dpsanders/ValidatedNumerics.jl) package for interval arithmetic, and [`IntervalConstraintProgramming.jl`](https://github.com/dpsanders/IntervalConstraintProgramming.jl) for constraint propagation.
  resources:
    - name: "Slides"
      url: "https://github.com/dpsanders/juliacon_2017_calculating_with_sets"
- speaker: "Kristoffer Carlsson"
  affiliation: "Chalmers University of Technology"
  title: "OhMyREPL.jl: This Is My REPL; There Are Many Like It, But This One Is Mine"
  abstract: >
    By default, Julia comes with a powerful REPL that itself is completely written in Julia.
    It has, among other things, tab completion, customizable keybindings and different prompt modes to use the shell or access the help system.
    However, with regards to visual customization there are not that many options for a user to tweak.
    To that end, I created the package OhMyREPL.jl.
    Upon loading, it hooks into the REPL and adds features such as syntax highlighting, matching bracket highlighting, functionality to modify input and output prompts and a new way of printing stacktraces and error messages.
    It also contains some non-visual features, like allowing text that has been copied from a REPL session to be directly pasted back into a REPL and quickly opening the location of stack frames from a stacktrace in an editor.
    The talk will give an overview of the different features, discuss which features managed to get upstreamed to Julia v0.6 and, if time allows, outline the internals of the package.
  bio: >
    Ph.D. student in computational mechanics at Chalmers University of Technology. Using Julia both for studies and as a hobby.
  resources:
    - name: "Slides"
      url: "https://github.com/KristofferC/OhMyREPL_JuliaCon2017"
- speaker: "Deniz Yuret"
  affiliation: "Koç University, Istanbul"
  title: "Knet.jl: Beginning Deep Learning with 100 Lines of Julia"
  abstract: >
    Knet (pronounced "kay-net") is the Koç University deep learning framework implemented in Julia by Deniz Yuret and collaborators. Knet uses dynamic computational graphs generated at runtime for automatic differentiation of (almost) any Julia code. This allows machine learning models to be implemented by only describing the forward calculation (i.e. the computation from parameters and data to loss) using the full power and expressivity of Julia. The implementation can use helper functions, loops, conditionals, recursion, closures, tuples and dictionaries, array indexing, concatenation and other high level language features, some of which are often missing in the restricted modeling languages of static computational graph systems like Theano, Torch, Caffe and Tensorflow. GPU operation is supported by simply using the KnetArray type instead of regular Array for parameters and data. High performance is achieved using custom memory management and efficient GPU kernels.
  bio: >
    Deniz Yuret received his BS, MS, and Ph.D. at MIT working at the AI Lab on machine learning and natural language processing during 1988-1999. He co-founded Inquira, Inc., a startup commercializing question answering technology which was later acquired by Oracle.  He is currently an associate professor of Computer Engineering at Koç University, Istanbul and founder of its Artificial Intelligence Laboratory. In his spare time he develops Knet.jl, a Julia deep learning framework that uses dynamic computational graphs generated at runtime for automatic differentiation of (almost) any Julia code.
  resources:
    - name: "Repo"
      url: "https://github.com/denizyuret/Knet.jl"
- speaker: "Spencer Lyon"
  affiliation: "NYU Stern"
  title: "The Dolo Modeling Framework"
  abstract: >
    We present a family of three Julia packages that together constitute a complete framework to describe and solve rational expectation models in economics. Dolang.jl is an equation parser and compiler that understands how to compile latex-like strings describing systems of equations into efficient Julia functions for evaluating the levels or derivatives of the equations. Dolo.jl leverages Dolang and implements a variety of frontier algorithms for solving a wide class of discrete time, continuous control rational expectations models. Finally, Dyno.jl builds upon Dolang to implement a Julia prototype of the Matlab-based dynare software library used extensively throughout academia and the public sector to approximate the solution to and estimate rational expectations models.
  bio: >
    Economics Ph.D. student at NYU Stern. Active Julia member since 0.2
- speaker: "Bart Janssens"
  affiliation: "Royal Military Academy"
  title: "QML.jl: Cross-platform GUIs for Julia"
  abstract: >
    The QML.jl (https://github.com/barche/QML.jl) package enables using the QML markup language from the Qt library to build graphical user interfaces for Julia programs. The package follows the recommended Qt practices and promotes separation between the GUI code and application logic. After a short introduction of these principles, the first topic of this talk will be the basic communication between QML and Julia, which happens through Julia functions and data (including composite types) stored in context properties. Using just a few basic building blocks, this makes all of the QML widgets available for interaction with Julia. The next part of the talk deals with Julia-specific extensions, such as the Julia ListModel, interfacing with the display system and GLVisualize and GR.jl support. These features will be illustrated using live demos, based on the examples in the QML.jl repository. Finally, some ideas for extending and improving the package will be listed, soliciting many contributions hopefully.

    The target audience for this talk is anyone interested in developing GUIs for their Julia application with a consistent look on OS X, Linux and Windows. All user-facing code is pure Julia and QML, no C++ knowledge is required to use the package.
  bio: >
    I am an associate professor at the mechanics department of the Royal Military Academy. For my Ph.D., I worked on Coolfluid, a C++ framework for computational fluid dynamics with a domain specific language. My interest in Julia is sparked by its powerful metaprogramming functionality coupled with C++-like performance, together with much better accessibility for students. To ease the transition to Julia, we are working on making some C++ libraries available in Julia. The QML.jl package is part of this effort. We also use Julia in our daily teaching activities, to provide students with interactive solutions to exercises.
  resources:
    - name: "Slides"
      url: "https://github.com/barche/qml-juliacon2017"
- speaker: "Jorge Perez and Luis Benet"
  affiliation: "UNAM (Mexico)"
  title: "TaylorIntegration.jl: Taylor's Integration Method in Julia"
  abstract: >
    In this talk we shall present TaylorIntegration.jl, an ODE integration package using Taylor's method in Julia. The main idea of Taylor's method is to approximate locally the solution by means by a *high-order* Taylor expansion, whose coefficients are computed recursively using automatic differentiation techniques. One of the principal advantages of Taylor's method is that, whenever high accuracy is required, the order of the method can be increased, which is more efficient computationally than taking smaller time steps.
    The accuracy of Taylor's method permits to have round-off errors per integration step. Traditionally, it has been difficult to
    make a generic Taylor integration package, but Julia permits this beautifully. We shall present some examples of the application of this method to ODE integration, including the whole computation of the Lyapunov spectrum, use of jet transport techniques, and parameter sensitivity. Open issues related to improving performance will be described.
  bio: >
    Jorge Perez is a Physics Ph.D. student at UNAM, Mexico, under supervision of Luis Benet and David P. Sanders, authors of TaylorSeries.jl and ValidatedNumerics.jl. His Ph.D. research project is related to understanding the dynamics of minor Solar System objects: comets, asteroids, etc. He is coauthor of TaylorIntegration.jl and a contributor to TaylorSeries.jl.

    Luis Benet is Associate Professor at the Instituto de Ciencias Físicas of the National University of Mexico (UNAM). He is mainly interested in classical and quantum chaos, including the dynamics of Solar System objects. He is
    coauthor of ValidatedNumerics.jl, TaylorSeries.jl and TaylorIntegration.jl, and has contributed to other Julia packages.
  resources:
    - name: "Slides"
      url: "http://nbviewer.jupyter.org/format/slides/github/PerezHz/TaylorIntegration.jl/blob/master/examples/JuliaCon2017/TaylorIntegration_JuliaCon.ipynb"
- speaker: "Camila Metello & Joaquim Garcia"
  affiliation: "PSR Inc."
  title: "Stochastic Optimization Models on Power Systems"
  abstract: >
    We will present 3 tools for decision making under uncertainty in the power systems area: SDDP, a tool for optimal hourly operation of complex power systems; OptGen, a computational tool for determining the least-cost expansion of a multi-regional hydrothermal system; OptFlow, a mathematical model to optimize operation of a generation/transmission system with AC electrical network constraints.

    These models have been used by system operators, regulators and investors in more than seventy countries in the Americas, Asia-Pacific, Europe and Africa, including some of the largest hydro based systems in the world, such as the Nordic pool, Canada, the US Pacific Northwest and Brazil. SDDP is also the model used by the World Bank staff in their planning studies of countries in Asia, Africa and Latin America.  OptGen had some interesting applications regional studies such as the interconnection of Central America, the Balkan regions, the interconnection of nine South American countries, Africa (Egypt-Sudan-Ethiopia and Morocco-Spain) and Central Asia.
    The original version of all 3 models was written in FORTRAN with the aid of some modelling tool or higher level API: AMPL for OptFlow, Mosel for OptGen and COIN-OR API for SDDP. Similar to any software, maintaining the code and adding new features became increasingly complex because they have to be built upon older data structures and program architectures.

    These concerns motivated PSR to develop an updated version of these programs written entirely in julia (with JuMP and MathProgBase) for three basic reasons: (i) the code is concise and very readable; (ii) the availability of an advanced optimization “ecosystem”; and (iii) excellent resources for distributed processing (CPUs and GPUs). We retained the use of Xpress by developing the Xpress.jl library. We also use MPI.jl for distributed processing (including multiple servers in AWS).

    The computational performance of the new code is matches the current ones’, which is very encouraging given that the current FORTRAN code has been optimized for several years based on thousands of studies. Also, the julia code incorporates several new modeling features that were easy to implement in all the 3 models: including SDP and SOCP relaxations for OPF and SDDiP method for stochastic integer optimization, confirming our expectation of faster model development.

    The new models were incorporated to an integrated planning system for Peru being developed by PSR, which will be delivered in August 2017. They are also being internally tested as a “shadow” to the current version for studies in several countries and was delivered for beta testing for some PSR clients. The official release is scheduled for the end of 2017.
  bio: >
    Camila graduated as an industrial engineer and has a MSc in Decision Analysis from PUC-Rio. Attended UC Berkeley for a semester during under graduation. Joined PSR in 2013, where, at present, works with the development of the models of optimization of hydrothermal dispatch under uncertainty with network constraints (SDDP model) and electric systems expansion planning (OPTGEN model).


    Joaquim has a BSc degree in electrical engineering and a BSc degree in mathematics, both from PUC -Rio and is currently working towards a PhD in electrical engineering with emphasis on decision support, also at PUC-Rio. During his undergraduate studies, he attended a year at UC Santa Barbara. He joined PSR in 2015 has been been working on the development of optimization models for hydro-thermal dispatch under uncertainty with transmission constraints  reliability analysis, electrical systems expansion planning and nonlinear optimal power flow. Before PSR Joaquim worked with decision support at LAMPS (Laboratory of applied mathematical programming and statistics, at PUC-Rio) and with OTDR and Signal Processing at LabOpt (Optoelectronics laboratory, at PUC-Rio).
- speaker: "Héctor Andrade Loarca"
  affiliation: "Technical University of Berlin (TUB)"
  title: "Fast Multidimensional Signal Processing with Shearlab.jl"
  abstract: >
    The Shearlet Transform was proposed in 2005 by the Professor Gitta Kutyniok (http://www3.math.tu-berlin.de/numerik/mt/mt/www.shearlet.org/papers/SMRuADaSO.pdf) and her colleagues as a multidimensional generalization of the Wavelet Transform, and since then it has been adopted by a lot of Companies and Institutes by its stable and optimal representation of multidimensional signals. Shearlab.jl is a already registered Julia package (https://github.com/arsenal9971/Shearlab.jl) based in the most used implementation of Shearlet Transform programmed in Matlab by the Research Group of Prof. Kutyniok (http://www.shearlab.org/software); improving it by at least double the speed on different experiments.

    As examples of applications of Shearlet Transform one has Image Denoising, Image Inpaiting and Video Compression; for instance I used it mainly to reconstruct the Light Field of a 3D Scene from Sparse Photographic Samples of Different Perspectives with Stereo Vision purposes. A lot of research institutes and companies have already adopted the Shearlet Transform in their work (e.g. Fraunhofer Institute in Berlin and Charité Hospital in Berlin, Mathematical Institute of TU Berlin) by its directional sensitivity, reconstruction stability and sparse representation.
  bio: >
    Ph.D. student in Mathematics at the Technical University of Berlin (TUB) with Professor Gitta Kutyniok  as advisor;  major in Mathematics and Physics from National University of México (UNAM); ex Data Scientist of a mexican Open Governance Start Up (OPI); with experience in Data Mining, Machine Learning, Computational Harmonic Analysis and Computer Vision. Currently developing Light Field Reconstruction algorithms using Digital Signal Processing tools for 3D Imaging and Stereo Vision. Is known by his colleagues for using Julia on everything. It was introduced to Julia by Professor David Philip Sanders and after both gave a course on Computational Statistical Physics using Julia at the National University of México  (UNAM) which convinced him to adopt Julia as his main programming language.
- speaker: "Ajay Mendez"
  affiliation: "Founder, Kinant.com"
  title: "Julia for Infrastructure: Experiences in Developing a Distributed Storage Service"
  abstract: >
    Julia is a language designed for numerical computing and it does that job pretty well. However, the emphasis on numerical computing and data science tends to overshadow the language’s other use cases. In this talk we share our experiences using Julia to build a distributed data fabric using commodity hardware. A data fabric is a distributed storage system that abstracts away the physical infrastructure and makes data available to applications using well known protocols such as NFS or S3. Our talk focuses on how we use Julia to implement a data fabric with specific examples. We will discuss some of the shortcomings and how we circumvented them. Finally we close by a cost benefit analysis of developing in Julia and how it can be a critical advantage in bringing products to market.
  bio: >
    Ajay works on systems and infrastructure software for fun and profit. He has dabbled in operating systems, memory allocators, file systems and distributed systems. He founded kinant.com in 2017 to simplify the deployment and usage of storage infrastructure.
  resources:
    - name: "Slides"
      url: "/2017/assets/slides/Julia for Infrastructure (Juliacon '17).pdf"
- speaker: "Simon Byrne, Ranjan Anantharaman"
  affiliation: "Julia Computing, Inc."
  title: "Miletus: A Financial Modelling Suite in Julia"
  abstract: >
    Miletus is a financial software suite in Julia, with a financial contract specification language and extensive modelling features. In this talk, we’ll discuss the design principles involved in how to model a contract from primitive components, and how Julia’s language features lend themselves intuitively to this task. We’ll then talk about the various features of the software suite such as closed form models, binomial trees and computation of price sensitivities (aka “the Greeks”), providing several examples and code snippets, along with comparisons with other popular frameworks in this space.

  bio: >
    Dr Simon Byrne is a quantitative software developer at Julia Computing, where he implements cutting edge numerical routines for statistical and financial models. Simon has a Ph.D. in statistics from the University of Cambridge, and has extensive experience in computational statistics and machine learning in both academia and industry. He has been contributing to the Julia project since 2012. Ranjan Anantharaman is a data scientist at Julia Computing where he works on numerical software in a variety of domains. His interests include scientific computing and machine learning. He has been contributing to the Julia project and ecosystem since 2015.
- speaker: "Júlio Hoffimann"
  affiliation: "Stanford University"
  title: "Image Quilting: Building 3D Geological Models One Tile at a Time"
  abstract: >
    ImageQuilting.jl is a high-performance implementation of texture synthesis and transfer for 3D images that is capable of matching pre-existing data in the canvas where the image is to be synthesized. It can optionally make use of GPUs through the OpenCL standard and is being currently used by the industry for fast generation of 3D geological models. In this talk, I will demonstrate some of the applications of this package in energy resources engineering and hydrogeology, and will highlight the qualities of the Julia programming language
    that enabled an unprecedented speed in this famous computer vision algorithm.
  bio: >
     I am a Ph.D. candidate in the Department of Energy Resources Engineering at Stanford University. In my research, I study the links between surface processes (i.e. flow and sediment transport) at the surface of the Earth and the resulting geostatistical properties at its subsurface. Part of this research consists of developing efficient algorithms for stochastic/physical simulation of 3D Earth models. For more information, please visit: https://juliohm.github.io
- speaker: "José Manuel Calderón Trilla"
  affiliation: "Galois, Inc."
  title: "Julia for Fully Homomorphic Encryption: Current Progress and Challenges"
  abstract: >
    Fully homomorphic encryption (FHE) is a cryptographic technique
    allowing a user to run arbitrary computations over encrypted data.
    This is particularly useful for computing statistical analytics over
    sensitive data. In this work, we introduce a Julia module, Fhe.jl,
    which supports running Julia functions over an FHE-encrypted data set.
    We do so by using symbolic execution to convert a Julia function into
    its circuit representation, which we then evaluate over the encrypted
    data. In this talk, we will discuss the progress we have made so far,
    some of the challenges we have run into, and how we hope to work with
    the Julia community to continue our efforts.
  bio: >
    José Manuel Calderón Trilla is a Research Scientist at Galois, Inc. working on Compilers, Static Analysis, and Formal Methods. He received his Ph.D. from the University of York in the UK for his work on Implicit Parallelism in lazy functional languages.
- speaker: "David Anthoff"
  affiliation: "UC Berkeley"
  title: "Query.jl: Query Almost Anything in Julia"
  abstract: >
    Query is a package for querying julia data sources. Its role is similar to LINQ in C# and dplyr in R. It can filter, project, join and group data from any iterable data source. It has enhanced support for querying arrays, DataFrames, DataTables, TypedTables, IndexedTables and any DataStream source (e.g. CSV, Feather, SQLite etc.). The package also defines an interface for tabular data that allows a) dispatch on any tabular data source and b) simple conversions of tabular data representations. The talk will first introduce Query from a user perspective and highlight different examples of queries that the package makes feasible. The second half of the talk will dive deep into the internals of the package and explain the various extension points that package provides.
  bio: >
    David Anthoff is an environmental economist who studies climate change and environmental policy. He co-develops the integrated assessment model FUND that is used widely in academic research and in policy analysis. His research has appeared in Science, the Journal of Environmental Economics and Management, Environmental and Resource Economics, the Oxford Review of Economic Policy and other academic journals. He contributed a background research paper to the Stern Review and has advised numerous organizations (including US EPA and the Canadian National Round Table on the Environment and the Economy) on the economics of climate change.

    He is an assistant professor in the Energy and Resources Group at the University of California, Berkeley. Previously he was an assistant professor in the School of Natural Resources and the Environment of the University of Michigan, a postdoc at the University of California, Berkeley and a postdoc at the Economic and Social Research Institute in Ireland. He also was a visiting research fellow at the Smith School of Enterprise and the Environment, University of Oxford.

    He holds a Ph.D. (Dr. rer. pol.) in economics from the University of Hamburg (Germany) and the International Max Planck Research School on Earth System Modelling, a MSc in Environmental Change and Management from the University of Oxford (UK) and a M.Phil. in philosophy, logic and philosophy of science from Ludwig-Maximilians-Universität München (Munich, Germany).
  resources:
    - name: "Slides"
      url: "/2017/assets/slides/AnthoffJuliacon2017.pdf"
    - name: "Slides (single-page)"
      url: "https://github.com/davidanthoff/talk-2017-juliacon"
- speaker: "Hilding Elmqvist"
  affiliation: "Mogram AB, Lund, Sweden"
  title: "Modia: A Domain Specific Extension of Julia for Modeling and Simulation"
  abstract: >
    Modia is a Julia package to model and simulate physical systems (electrical, mechanical, thermo-dynamical, etc.) described by differential and algebraic equations. A user defines a model on a high level with model components (such as a mechanical body, an electrical resistance, or a pipe) that are physically connected together. A model component is constructed by "expression = expression" equations. The defined model  is symbolically processed, JIT compiled and simulated with Sundials IDA solver with the KLU sparse matrix package. By this approach it's possible and convenient to build models with hundred thousands of equations describing the dynamics of a car, an airplane, a power plant, etc. and simulate them. The authors used previous experience from the design of the modeling language Modelica (www.Modelica.org) to develop Modia.

    In the presentation it is shown how a user can build models and simulate physical systems, including mechanical systems and electrical circuits. Furthermore, the design of Modia is sketched: The Modia language is a domain specific extension of Julia using macros. With graph theoretical algorithms, some of them recently developed by the authors, equations are pre-processed (including analytic differentiation if necessary) and transformed into a special form that can be simulated by IDA. Hereby the sparsity structure of the original (Modia) equations, as well as the nature of array equations are kept intact.
  bio: >
    Hilding Elmqvist attained his Ph.D. at the Department of Automatic Control, Lund Institute of Technology in 1978. His Ph.D. thesis contains the design of a novel object-oriented model language called Dymola and algorithms for symbolic model manipulation. It introduced a new modeling methodology based on connecting submodels according to the corresponding physical connections instead of signal flows. Submodels were described declaratively by equations instead of assignment statements. Elmqvist spent one year in 1978-1979 at the Computer Science Department at Stanford University, California. 

    In 1992, Elmqvist founded Dynasim AB in Lund, Sweden. The primary product is Dymola for object-oriented modeling allowing graphical composition of models and 3D visualization of model dynamics. Elmqvist took the initiative in 1996 to organize an international effort to design the next generation object-oriented language for physical modeling: Modelica. In April 2006, Dynasim AB was acquired by Dassault Systemes. In January 2016, Elmqvist founded Mogram AB. Current activities include designing and implementing an experimental modeling language called Modia.
- speaker: "Laurent Heirendt"
  affiliation: "Luxembourg Centre for Systems Biomedicine"
  title: "COBRA.jl: Accelerating Systems Biology"
  abstract: >
    Laurent Heirendt, Sylvain Arreckx, Ines Thiele, Ronan M.T.
    Fleming

    Systems Biologists in the COnstraint-Based Reconstruction and Analysis (COBRA) [7] community are gearing up to develop computational models of large and huge-scale biochemical networks with more than one million biochemical reactions. The growing model size puts a strain on efficient simulation and network exploration times to the point that accelerating existing COBRA methods became a priority. Flux balance analysis and its variants are widely used methods for predicting steady-state reaction rates in biochemical reaction networks. The exploration of high dimensional networks has long been hampered by performance limitations of current implementations in Matlab/C (The COBRA Toolbox [8] and fastFVA [3]) or Python (cobrapy [2]). Julia [1] is the language that fills the gap between complexity, performance, and development time. DistributedFBA.jl [4], part of the novel COBRA.jl package, is a high-level, high-performance, open-source Julia implementation of flux balance analysis, which is a linear optimization problem. It is tailored to solve multiple flux balance analyses on a subset or all the reactions of large and huge-scale networks, on any number of threads or nodes using optimization solver interfaces implemented in MathProgBase.jl [5]. Julia's parallelization capabilities led to a speedup in latency that follows Amdahl's law. For the first time, a flux variability analysis (two flux balance analyses on each biochemical reaction) on a model with more than 200k biochemical reactions [6] has been performed. With Julia and COBRA.jl, the reconstruction and analysis capabilities of large and huge-scale models in the COBRA community are lifted to another level.

    Code and benchmark data are freely available on github.com/opencobra/COBRA.jl

    References:

      - [1] Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B., "Julia: A Fresh Approach to Numerical Computing", arXiv:1411.1607 [cs]  (2014). arXiv: 1411.1607
      - [2] Ebrahim, Ali and Lerman, Joshua A. and Palsson, Bernhard O. and Hyduke, Daniel R., "COBRApy: COnstraints-Based Reconstruction and Analysis for Python", BMC Systems Biology  7 (2013), pp. 74.
      - [3] Gudmundsson, Steinn and Thiele, Ines, "Computationally efficient flux variability analysis", BMC Bioinformatics  11, 1 (2010), pp. 489.
      - [4] Heirendt, Laurent and Thiele, Ines and Fleming, Ronan M. T., "DistributedFBA.jl: high-level, high-performance flux balance analysis in Julia", Bioinformatics  btw838 (2017).
      - [5] Lubin, Miles and Dunning, Iain, "Computing in Operations Research using Julia", INFORMS Journal on Computing  27, 2 (2015), pp. 238--248. arXiv: 1312.1431
      - [6] Magnúsdóttir, Stefanía and Heinken, Almut and Kutt, Laura and Ravcheev, Dmitry A. and Bauer, Eugen and Noronha, Alb…, "Generation of genome-scale metabolic reconstructions for 773 members of the human gut microbiota", Nat Biotech  35, 1 (2017), pp. 81--89.
      - [7] Palsson, Bernhard Ø, Systems Biology: Constraint-based Reconstruction and Analysis (Cambridge, England: Cambridge University Press, 2015).
      - [8] Schellenberger, Jan and Que, Richard and Fleming, Ronan M. T. and Thiele, Ines and Orth, Jeffrey D. and Feist, Adam M. and Ziel…, "Quantitative prediction of cellular metabolism with constraint-based models: the COBRA Toolbox v2.0", Nat. Protocols  6, 9 (2011), pp. 1290--1307. 00182
  bio: >
    Laurent Heirendt was born in 1987 in Luxembourg City, Luxembourg (Europe). He received his BSc in Mechanical Engineering from the Ecole Polytechnique Fédérale de Lausanne, Switzerland in 2009. A year later, he received his MSc in Advanced Mechanical Engineering from Imperial College London in the UK, where his research and thesis focused on developing a general dynamic model for shimmy analysis of aircraft landing gear that is still in use today. He received his Ph.D. in 2014 in Aerospace Science from the University of Toronto, Canada. He developed a thermo-tribomechnical model of an aircraft landing gear, which led to a patent pending design of a critical aircraft landing gear component.
    He then worked in industry and oversaw the structural analysis of large aircraft docking structures.

    Recently, Laurent started as a Research Associate at the Luxembourg Centre for Systems Biomedicine, where he works in the numerical optimization of large biochemical networks using Julia. Besides his mother tongue Luxembourgish, he is fluent in English, French and German, and he is currently learning Brazilian Portuguese. 
  resources:
    - name: "Slides"
      url: "https://opencobra.github.io/COBRA.jl/juliaCon2017/presentation.pdf"
- speaker: "Jarrett Revels"
  affiliation: "MIT"
  title: "Mixed-Mode Automatic Differentiation in Julia"
  abstract: >
    Julia's unique execution model, metaprogramming facilities, and type system make it an ideal candidate language for native automatic differentiation (AD). In this talk, we'll discuss a variety of Julia-specific tricks employed by ForwardDiff and ReverseDiff to differentiate user-provided Julia functions. Topics covered include the implementation of a native Julia execution tracer via operator overloading, functor-based directives for specialized instruction taping, SIMD vectorization and instruction elision for inlined dual number operations, and vectorized differentiation of linear algebraic expressions. I'll close the talk with a glimpse into the future of AD in Julia and JuMP, highlighting the effect new features may have on other downstream projects like Celeste, Optim and RigidBodyDynamics.
  bio: >
    I like to make Julia code differentiate itself.
  resources:
    - name: "Slides"
      url: "https://github.com/jrevels/AutoDiffPresentations/blob/master/juliacon_2017_slides.pdf"
- speaker: "Madeleine Udell"
  affiliation: "Cornell University"
  title: "Julia: The Type of Language for Mathematical Programming"
  abstract: >
    Julia was designed to be the right language for programming mathematics. In this talk, I’ll argue that its sophisticated type system allows mathematicians to program in the same way they write mathematics. This simplicity has two consequences. First, it has made Julia an attractive ecosystem in which to write mathematical packages: Julia is now the language with the most comprehensive, robust, and user-friendly ecosystem of packages for mathematical programming (or optimization, in modern lingo). Second, it has made Julia the right language in which to express many mathematical problems. The lightweight type system makes it easy to write code that is clearer than pseudocode.

    This talk will present three case studies in optimization. We hope the audience will leave the talk with a new appreciation of Julia’s type system, as well as a new toolkit of packages to use for data fitting and optimization.

    1. Convex is a widely used library for convex optimization in Julia. In that package, the type system is used to create and recursively analyze the abstract syntax tree representing an optimization problem. Notions such as the sign of a real number, or the convexity or concavity of a function, are represented as types; and the convexity of an expression can be analyzed using a simple recursion over the tree of types.

    2. LowRankModels is a statistical package for imputing missing entries in large, heterogeneous tabular data set. LowRankModels uses type information about a DataFrame to automatically select the appropriate optimization problem to solve in order to find the best completion for the data table. These optimization problems are parametrized by a set of loss functions and regularizers. Using the type system, we are able to write algorithms that work seamlessly for any loss function or regularizer a user may dream up.

    3. Sketched approximations are a class of fast algorithms for producing a low rank approximation to a matrix - like an eigenvalue decomposition, but faster. We’ll show how to use parametric types to write all the special cases of the algorithm without introducing redundant code. Notably, these parametric types make it easier to understand the flow of the algorithm, and have essentially no analogue in “pseudocode” notation. Together with Julia’s simple mathematical syntax and support for unicode (eg, Greek) letters, we’ll see that the Julia code functions not only as an implementation of the method, but as a better version of pseudocode.
  bio: >
    Madeleine Udell is Assistant Professor of Operations Research and Information Engineering and Richard and Sybil Smith Sesquicentennial Fellow at Cornell University. She studies optimization and machine learning for large scale data analysis and control, with applications in marketing, demographic modeling, medical informatics, and engineering system design. Her recent work on generalized low rank models (GLRMs) extends principal components analysis (PCA) to embed tabular data sets with heterogeneous (numerical, Boolean, categorical, and ordinal) types into a low dimensional space, providing a coherent framework for compressing, denoising, and imputing missing entries. She has developed of a number of open source libraries for modeling and solving optimization problems, including Convex.jl, one of the top ten tools in the new Julia language for technical computing, and is a member of the JuliaOpt organization, which curates high quality optimization software.

    Madeleine completed her Ph.D. at Stanford University in Computational & Mathematical Engineering in 2015 under the supervision of Stephen Boyd, and a one year postdoctoral fellowship at Caltech in the Center for the Mathematics of Information hosted by Professor Joel Tropp. At Stanford, she was awarded a NSF Graduate Fellowship, a Gabilan Graduate Fellowship, and a Gerald J. Lieberman Fellowship, and was selected as the doctoral student member of Stanford's School of Engineering Future Committee to develop a road-map for the future of engineering at Stanford over the next 10–20 years. She received a B.S. degree in Mathematics and Physics, summa cum laude, with honors in mathematics and in physics, from Yale University.
- speaker: "Jonathan Malmaud"
  affiliation: "MIT"
  title: "Modern Machine Learning in Julia with TensorFlow.jl"
  abstract: >
    By many measures, TensorFlow has grown over the last year to become the most popular library for training machine-learning models. TensorFlow.jl provides Julia with a simple yet feature-rich interface to TensorFlow that takes advantage of Julia's multiple dispatch, just-in-time compilation, and metaprogramming capabilities to provide unique capabilities exceeding TensorFlow's own native Python API.
    This talk will demonstrate TensorFlow.jl by guiding listeners through training a realistic model of image captioning , showing how to 1) construct the model with native Julia control flow and indexing, 2) visualize the model structure and parameters in a web browser during training,  and 3) seamlessly save and share the trained model with Python. No prior experience with TensorFlow is assumed.
  bio: >
    Ph.D. candidate at MIT studying artificial intelligence
  resources:
    - name: "Slides"
      url: "https://github.com/malmaud/juliacon2017"
- speaker: "Mike Innes"
  affiliation: "Julia Computing, Inc."
  title: "Flux: Machine Learning with Julia"
  abstract: >
    Flux.jl is a new Julia package for machine learning. It aims to provide strong tooling and support for debugging, high-level features for working with very complex networks, and state of the art performance via backends like TensorFlow or MXNet, while also providing a very high level of interoperability so that approaches can easily be mixed and matched. This talk will introduce Flux from the ground up and demonstrate some of its more advanced features.
  bio: >
    I work with Julia Computing on Julia's IDE, Juno, as well as various projects within the machine learning ecosystem.
- speaker: "Ehsan Totoni"
  affiliation: "Intel Labs"
  title: "HiFrames: High Performance Distributed Data Frames in Julia"
  abstract: >
    Data frames are essential tools for data scientists, but existing data frames packages in Julia (and other languages) are sequential and do not scale to large data sets. Alternatively, data frames in distributed frameworks such as Spark are slow and not integrated with other computations flexibly. We propose a novel compiler-based approach where we integrate data frames into the High Performance Analytics Toolkit (HPAT) to build HiFrames. It automatically parallelizes and compiles relational operations along with other array computations in end-to-end data analytics programs, and generates efficient MPI/C++ code. We demonstrate that HiFrames is significantly faster than alternatives such as Spark on clusters, without forcing the programmer to switch to embedded SQL for part of the program. HiFrames is 3.6x to 70x faster than Spark SQL for basic relational operations, and can be up to 20,000x faster for advanced analytics operations, such as weighted moving averages (WMA), that the map-reduce paradigm cannot handle effectively. We will discuss how Julia’s powerful macro and compilation system facilitates developing HiFrames.
  bio: >
    Ehsan Totoni is a Research Scientist at Intel Labs. He develops programming systems for large-scale HPC and big data analytics applications with a focus on productivity and performance. He received his Ph.D. in Computer Science from the University of Illinois at Urbana-Champaign in 2014.
- speaker: "Robin Deits and Twan Koolen"
  affiliation: "MIT CSAIL"
  title: "The Present and Future of Robotics in Julia"
  abstract: >
    We (Twan and Robin) are graduate students in the Robot Locomotion Group at MIT. Our research focuses on modeling and optimization for the simulation and control of walking (and sometimes flying) robots. We've been using Julia in our research over the past year, and we're excited to share what we've learned, what we've built, and what we're hoping to see in the future of Julia.

    Specifically, we'd like to share some of our work on:

    * Robot dynamics and simulation in Julia: https://github.com/tkoolen/RigidBodyDynamics.jl

    * 3D visualization and manipulation of robot models from Julia: https://github.com/rdeits/RigidBodyTreeInspector.jl https://github.com/rdeits/DrakeVisualizer.jl

    * Optimization in Julia: https://github.com/rdeits/NNLS.jl

    * Collision algorithms in Julia: https://github.com/rdeits/EnhancedGJK.jl https://github.com/rdeits/AdaptiveDistanceFields.jl


    We would also like to talk about how some of the best parts of the Julia ecosystem have made our work possible, like JuMP.jl, ForwardDiff.jl, and StaticArrays.jl.

    And, finally, we plan to discuss what we hope to see in Julia's future, including what the role of Julia can be inside a real-time robot controller.

  bio: >
    We're graduate students in the Robot Locomotion Group at MIT, where we work on simulation, planning, and control of walking and flying robots.
  resources:
    - name: "Slides"
      url: "https://github.com/tkoolen/RoboticsJuliaCon2017.jl/"
- speaker: "Hong Ge, Zoubin Ghahramani, Kai Xu"
  affiliation: "University of Cambridge"
  title: "Turing: a Fresh Approach to Probabilistic Programming"
  abstract: >
    Turing is a new probabilistic programming language (PPL) based on Julia, a framework which allows users to define probabilistic models and perform inference automatically. Thanks to Julia's meta-programming support, Turing has a very friendly front-end modelling interface. Meanwhile, coroutines are used in Turing's inference engine development to achieve the state-of-the-art sampling performance. Also, we have recently introduced a new Gibbs interface, which allows user to compose different samplers and run them in the same time. In this talk, we will discuss our motivation of developing Turing in Julia, introduce the design and architecture of Turing, and present some practical examples of how probabilistic modelling is performed in Turing.
  bio: >
    Developers of the Turing project form Cambridge Machine Learning Group
- speaker: "Jeff Bezanson"
  affiliation: "Julia Computing, Inc."
  title: "The State of the Type System"
  abstract: >
    Julia 0.6 includes a long-needed overhaul of the type system. While the effects of this change are not always visible, the new system eliminates classes of bugs and increases the expressiveness of types and method signatures. I plan to briefly explain how the new system works and what you can do with it. But more importantly, I want to ask: where do we go from here? Will we ever need another overhaul? I'll present some possible future features and other related speculations. Topics may include record types, more powerful tuple types, protocols, ugly corner cases, and method specificity and ambiguity.
  bio: >
    Jeff is one of the creators of Julia, co-founding the project at MIT in 2009 and eventually receiving a Ph.D. related to the language in 2015. He continues to work on the compiler and system internals, while also working to expand Julia's commercial reach as a co-founder of Julia Computing, Inc.
  resources:
    - name: "Slides"
      url: "https://docs.google.com/presentation/d/14vKJZxSNLkB-zu7asaLcvg6iJUyYfmpOu8NhN5hmItY"
- speaker: "Tim Besard"
  affiliation: "Ghent University"
  title: "Programming NVIDIA GPUs in Julia with CUDAnative.jl"
  abstract: >
    GPUs have typically been programmed using low-level languages like CUDA and OpenCL, providing full control over the hardware at the expense of developer efficiency. CUDAnative.jl makes it possible to program GPUs directly from Julia, in the case you need the flexibility to write your own kernel functions, without having to fall back to CUDA C or binary libraries. In this talk, I will give an overview of CUDAnative.jl with its features and restrictions, explain the technology behind it, and sketch our future plans.
  bio: >
    Ph.D. student at Ghent University
  resources:
    - name: "Slides"
      url: "https://maleadt.github.io/notebooks/2017-juliacon/talk_cudanative.pdf"
    
- speaker: "Simon Danisch"
  affiliation: "JuliaLang"
  title: "GLVisualize 1.0"
  abstract: >
    GLVisualize is a visualization framework written purely in Julia + OpenGL.
    There are a lot of new changes that I want to talk about:
     * New trait system for more modularity and code clarity
     * Different backends for GLVisualize - conquering the Web & PDFs!
     * A new API for simpler drawing
     * Tight integration with GPUArrays, pre-processing on the GPU
     * Higher level plotting interface
  bio: >
    Developer of GLVisualize & GPUArrays
    
- speaker: "Stefan Karpinski"
  affiliation: "Julia Computing, Inc. / NYU"
  title: "Pkg3: Julia's New Package Manager"
  abstract: >
    This talk covers the design and implementation of Pkg3, the third (and hopefully final!) major iteration of Julia's built-in package manager. We'll begin with some history: what worked and didn't work in the two previous iterations of the package manager. Pkg3 tries to marry the better parts of systems like Python's virtualenv and Rust's cargo, while supporting federated and layered package registries, and supporting interactive usage as well as reproducible environments and reliable deployment of code in production. We'll nerd out a bit with some graph theory and how difficult it is to select compatible sets of package versions, and how much harder still it is to make version resolution understandable and predictable. But it won't be all theory – we'll also cover imminently practical subjects like "how do I install packages?"
  bio: >
    co-creator of Julia, co-founder of Julia Computing
- speaker: "Jameson Nash"
  affiliation: "Julia Computing, Inc."
  title: "AoT or JIT : How Does Julia Work?"
  abstract: >
    Julia uses a unique mix of techniques adopted from conventional static and dynamic to provide a special blend of high-performance and flexible compute kernels. This allows it to simultaneously have a fully ahead-of-time-compiled code model – while permitting (even encouraging) code updates at runtime – and a fully runtime-interpreted interface – while permitting extensive compile-time optimization. In this talk, I will examine some of the trade-offs and limitations this requires of user code, especially on common first-class code evaluation features – such as `eval` and incremental pre-compilation – as well as advanced features – such as `@generated` functions and `@pure`. We will also try to take a look at the internal layout and implementation of some of these data structures, and how the compiler works to maintain their correctness over time, despite other changes to the system.
  bio: >
    I've been a Julia contributor since before it was cool. Now, I'm working for Julia Computing, as the static compilation champion, compiler correctness fiend, and performance cliff jumper.
  resources:
    - name: "Slides"
      url: "https://vtjnash.github.io/juliacon-talks-vtjnash/assets2017/player/KeynoteDHTMLPlayer.html"
- speaker: "Jiahao Chen"
  affiliation: "Capital One"
  title: "Taking Vector Transposes Seriously"
  abstract: >
    from @jiahao:

    We have really thought carefully about what the transpose of a vector should mean in a programming language. The pre-0.6 behavior that vector'vector yields a vector, vector' yields a matrix, and vector'' yields a matrix are all bad mathematics and produced no shortage of confusion by end users.

    I present a summary of our research at the MIT Julia Labs into issue #4774, as a language design question that is informed by a comprehensive understanding of user expectations. Our main result is a short proof that it is impossible to avoid either new types, "ugly mathematics" (violation of Householder notation) or type instability. A single Array type is incompatible with Householder notation that produces the expected types from typical linear algebraic expressions. Furthermore, Householder notation intrinsically requires a conflation of 1x1 matrices and true scalars.

    I also provide historical evidence the notion of "ugly mathematics" is neither static nor objective. In reality, linear algebra has changed greatly over the past centuries, demonstrating the impermanence of even elementary concepts of what matrices and vectors are and how they have been influenced by notation - a discussion forced into consciousness through the lens of programming language design, types, and formal program semantics.

    I review the resolution of #19670 in the context of other designs in other programming languages, showing that all these designs turn out to locally optimal in conflating as much of Householder notation and array semantics as possible.

    Joint work with Alan Edelman, Andy Ferris, and a few other people.
  bio: >
    Data Scientist at Capital One, formerly Research Scientist at MIT
  resources:
    - name: "Slides"
      url: "https://www.slideshare.net/acidflask/taking-vector-transposes-seriously"
# - speaker: "Eddie Elizondo"
#   affiliation: "Homer Logistics"
#   title: "Using Julia to Bridge Research and Production Environments for an On-demand Delivery Network"
#   abstract: >
#     Quickly moving ideas from research to implementation has always been challenging, usually requiring intensive code rewrites that impede development or constrain research ideas considered too time-intensive to implement.  Homer Logistics is an on-demand delivery provider whose systems power more than 100,000 monthly deliveries across 11 markets across the United States.  We have used Julia extensively to bridge the gap between research and implementation to improve and iterate our methods as quickly as possible.
# 
#     Because of Julia’s flexibility, package library for optimization, and strong performance, we can repurpose much of our research code from a simulated environment for our production systems.  In production, we use a collection of Julia microservices built from Docker images that are then deployed and managed using Kubernetes.  The Julia microservices function as specialized computational engines for different components of the delivery network, helping us solve tens of thousands of linear programs daily to remain dynamically responsive to our on-demand environment.  These microservices communicate with other systems using Redis and HTTP.  We will talk about our experience using Julia in research and production and challenges that are our concerns for continuing to use Julia in the future.
#   bio: >
#     4 years of industry experience: 2 years in operations and analytics consulting and most recently, developing dynamic dispatching, routing, and allocation models for an on-demand transportation startup.  Will begin a Ph.D. program in operations research this fall.  University of Pennsylvania '13 (B.S., concentrations in statistics, operations research, finance)
- speaker: "Rainer Engelken"
  affiliation: "Max Planck Institute for Dynamics and Self-Organization"
  title: "Event-based Simulation of Spiking Neural Networks in Julia"
  abstract: >
    Information in the brain is processed by the coordinated activity of large neural circuits. Neural network models help to understand, for example, how biophysical features of single neurons and the network topology shape the collective circuit dynamics. This requires solving large systems of coupled differential equations which is numerically challenging.

    Here, we introduce a novel efficient method for numerically exact simulations of sparse neural networks that bring to bear Julia’s different data structures and high performance. The new algorithm reduces the computational cost from O(N) to O(log(N)) operations per network spike. This is achieved by mapping the neural dynamics to pulse-coupled phase oscillators and using mutable binary heaps for efficient state updates.
    Thereby numerically exact simulations of large spiking networks and the characterization of their chaotic phase space structure become possible. For example, calculating the largest Lyapunov exponent of a spiking neural network with one million neurons is sped up by more than four orders of magnitude compared to previous implementations in other programming languages (C++, Python, Matlab).
  bio: >
    Rainer just finished his Ph.D. in at the Max Planck Institute for Dynamics and Self-Organization (Göttingen) on 'Chaotic neural circuit dynamics' after studying physics at various places. He has been using Julia since 2014, as it minimizes both programming time and CPU time and allows easy debugging, profiling and visualization under one roof.
  resources:
    - name: "Slides"
      url: "https://github.com/RainerEngelken/JuliaCon2017"
- speaker: "Mihir Paradkar"
  affiliation: "Cornell University"
  title: "GraphGLRM: Making Sense of Big Messy Data"
  abstract: >
    Many projects in research and development require analysis of tabular data. For example, medical records can be viewed as a collection of variables like height, weight, and age for different patients. The values may be boolean (yes or no), numerical (100.3), categorical (A, B, O), or ordinal (early, middle, late). Some values may also be missing. However, analysis and feature extraction is made easier by knowing relationships between variables, for example, that weight increases with height. GraphGLRM is a framework that leverages structure in data to de-noise, compress, and estimate missing values. Using Julia’s flexibility and speed, we developed this package quickly and with sufficient performance for real-world data processing needs. GraphGLRMs are now robust and versatile enough to work with sparse, heterogeneous data. We will also discuss updates to Julia data structures and tooling that would ease package development and further empower the GraphGLRM framework.
    More about GraphGLRMs: https://github.com/mihirparadkar/GraphGLRM.jl
    More about LowRankModels: https://github.com/madeleineudell/LowRankModels.jl
  bio: >
    Mihir Paradkar recently graduated from Cornell University in Biological Engineering. He has been user of Julia since v0.3.5 and is a developer of GraphGLRM.jl and LowRankModels.jl . He will be starting as a software engineering in data mining at Yelp late this summer.
  resources:
    - name: "Slides"
      url: "https://docs.google.com/presentation/d/1n8Q7lf1O1tS-OKQOAkZWydvy5lwQY4UlMCKE3W129Fw"
- speaker: "Udayan Kumar/ Paul Shealy"
  affiliation: "Microsoft"
  title: "Building End to End Data Science Solutions in the Azure Cloud with Julia"
  abstract: >
    Increasingly organizations are using cloud platforms to store their data and perform analytics driven by cost, scale, and manageability considerations. Business applications are being retooled to leverage the vast enterprise / public data, artificial intelligence (AI), and machine learning (ML) algorithms.  To build and deploy large scale intelligent applications, data scientists and analysts today need to be able to combine their knowledge of analytical languages and platforms like Julia with that of the cloud.

    In this talk, data scientists and analysts will learn how to build end-to-end analytical solutions using Julia on scalable cloud infrastructure. Developing such solutions usually requires one to understand how to seamlessly integrate Julia with various cloud technologies. After attending the talk, the attendees should have a good understanding of all the major aspects needed to start building intelligent applications on the cloud using Julia, leveraging appropriate cloud services and tool-kits. We will also briefly introduce the Azure Data Science Virtual Machine [DSVM](http://aka.ms/dsvm) which provides a comprehensive development/experimentation environment with several pre-configured tools to make it easy to work with different cloud services (SQL Data Warehouse, Spark, Blobs etc.) from Julia and other popular data analytics languages. Join this demo heavy session where we cover the end to end data science life-cycle and show how you can access storage and compute services on the Azure cloud using Julia from the DSVM.  A self-guided tutorial building upon the examples in the demo will be published online for attendees to continue their learning offline.

  bio: >
    Udayan is a Software Engineer with Algorithms and Data Science group at Microsoft.   Before coming to Microsoft, he was designing predictive algorithms to detect threats and malignant apps at a mobile security startup in Chicago.
    He has a MS and a Ph.D. in Computer Engineering from University of Florida, Gainesville, FL. His research was focused on Trust, Privacy and Behavior mining in Mobile Networks.

    Paul is a senior software engineer in Microsoft’s Algorithms and Data Science group, where he is the lead engineer for the Data Science Virtual Machine and works on a variety of solutions for easier machine learning and data science. He was previously the project lead for the Planner service in Office 365. While on Planner he also worked on disaster recovery, topology, storage, and several other core service components. He holds computer science degrees from Clemson and Duke.
